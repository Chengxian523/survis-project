

@article{Xie2024Grade,
  abstract ={This paper proposes an LLM-based grading system that addresses the entire grading procedure, including the following key components: (1) developing grading rubrics that not only consider the questions but also the student answers, which can more accurately reflect students' performance; (2) under the guidance of grading rubrics, providing accurate and consistent scores for each student, along with customized feedback; (3) conducting post-grading review to better ensure accuracy and fairness.},
  author = {Xie, Wenjing and Niu, Juxin and Xue, Chun Jason and Guan, Nan},
  doi = {10.48550/arXiv.2405.19694},
  journal = {arXiv preprint arXiv:2405.19694},
  keywords = {type:Framework，LLM, automated grading, rubric design, assessment fairness},
  number = {2405.19694},
  publisher = {arXiv},
  volume = {abs/2405.19694},
  series = {cs.AI},
  title = {Grade Like a Human: Rethinking Automated Assessment with Large Language Models},
  url = {https://arxiv.org/abs/2405.19694},
  year = {2024}
}

@article{Yeung2025ZeroShot,
  abstract = {This study introduces a Zero-Shot Large Language Model (LLM)-Based Automated Assignment Grading (AAG) system. The framework leverages prompt engineering to evaluate both computational and explanatory student responses without requiring additional training or fine-tuning. The AAG system delivers tailored feedback that highlights individual strengths and areas for improvement, thereby enhancing student learning outcomes. Comprehensive evaluations, including survey responses from higher education students, indicate significant improvements in motivation, understanding, and preparedness compared to traditional grading methods. The results validate the AAG system's potential to transform educational assessment by prioritizing learning experiences and providing scalable, high-quality feedback.},
  author = {Yeung, Calvin and Yu, Jeff and Cheung, King Chau and Wong, Tat Wing and Chan, Chun Man and Wong, Kin Chi and Fujii, Keisuke},
  doi = {10.48550/arXiv.2501.14305},
  journal = {arXiv preprint arXiv:2501.14305},
  keywords = {type:Application，LLM, zero-shot learning, automated grading, personalized feedback},
  number = {2501.14305},
  publisher = {arXiv},
  volume = {abs/2501.14305},
  series = {cs.CY},
  title = {A Zero-Shot LLM Framework for Automatic Assignment Grading in Higher Education},
  url = {https://arxiv.org/abs/2501.14305},
  year = {2025}
}

@article{Policar2025Bioinformatics,
  abstract = {Providing students with individualized feedback through assignments is a cornerstone of education that supports their learning and development. Studies have shown that timely, high-quality feedback plays a critical role in improving learning outcomes. However, providing personalized feedback on a large scale in classes with large numbers of students is often impractical due to the significant time and effort required. Recent advances in natural language processing and large language models (LLMs) offer a promising solution by enabling the efficient delivery of personalized feedback. These technologies can reduce the workload of course staff while improving student satisfaction and learning outcomes. Their successful implementation, however, requires thorough evaluation and validation in real classrooms.
We present the results of a practical evaluation of LLM-based graders for written assignments in the 2024/25 iteration of the Introduction to Bioinformatics course at the University of Ljubljana. Over the course of the semester, more than 100 students answered 36 text-based questions, most of which were automatically graded using LLMs. In a blind study, students received feedback from both LLMs and human teaching assistants without knowing the source, and later rated the quality of the feedback. We conducted a systematic evaluation of six commercial and open-source LLMs and compared their grading performance with human teaching assistants. Our results show that with well-designed prompts, LLMs can achieve grading accuracy and feedback quality comparable to human graders. Our results also suggest that open-source LLMs perform as well as commercial LLMs, allowing schools to implement their own grading systems while maintaining privacy.},
  author = {Poličar, Pavlin G. and Špendl, Martin and Curk, Tomaž and Zupan, Blaž},
  doi = {10.48550/arXiv.2501.14499},
  journal = {arXiv preprint arXiv:2501.14499},
  keywords = {type:Evaluation，LLM, automated grading, bioinformatics education, student feedback},
  number = {2501.14499},
  publisher = {arXiv},
  volume = {abs/2501.14499},
  series = {cs.LG},
  title = {Automated Assignment Grading with Large Language Models: Insights From a Bioinformatics Course},
  url = {https://arxiv.org/abs/2501.14499},
  year = {2025}
}

@article{Gobrecht2024AIGrading,
  abstract = {We introduce a novel automatic short answer grading (ASAG) system. The system is based on a fine-tuned open-source transformer model which we trained on a large set of exam data from university courses across a large range of disciplines. We evaluated the trained model's performance against held-out test data in a first experiment and found high accuracy levels across a broad spectrum of unseen questions, even in unseen courses.},
  author = {Gobrecht, Alexandra and Tuma, Felix and Möller, Moritz and Zöller, Thomas and Zakhvatkin, Mark and Wuttig, Alexandra and Sommerfeldt, Holger and Schütt, Sven},
  doi = {10.48550/arXiv.2405.04323},
  journal = {arXiv preprint arXiv:2405.04323},
  keywords = {type:Technique，AI grading, transformer models, short-answer assessment, grading consistency},
  number = {2405.04323},
  publisher = {arXiv},
  volume = {abs/2405.04323},
  series = {cs.AI},
  title = {Beyond Human Subjectivity and Error: A Novel AI Grading System},
  url = {https://arxiv.org/abs/2405.04323},
  year = {2024}
}

@article{BERJ2024LLMComparison,
  abstract = {This study compares how the generative AI (GenAI) large language model (LLM) ChatGPT performs in grading university exams compared to human teachers. Aspects investigated include consistency, large discrepancies, and length of answer. Implications for higher education, including the role of teachers and ethics, are also discussed. Three Master's-level exams were scored using ChatGPT 3.5, and the results were compared with the teachers' scoring, and the grading teachers were interviewed.},
  author = {Author(s) not specified},
  doi = {10.1002/berj.4069},
  journal = {British Educational Research Journal},
  keywords = {type:Evaluation，LLM, ChatGPT, exam grading, human comparison},
  number = {4069},
  publisher = {Wiley},
  volume = {50},
  series = {BERJ},
  title = {Grading Exams Using Large Language Models: A Comparison with Human Teachers},
  url = {https://bera-journals.onlinelibrary.wiley.com/doi/10.1002/berj.4069},
  year = {2024}
}

@article{Hovsepian2024Calibration,
  abstract = {Large Language Models (LLMs) have been employed as crowdsourced annotators to alleviate the burden of human labeling. However, the broader adoption of LLM-based automated labeling systems encounters two main challenges: (1) LLMs are prone to producing unexpected and unreliable predictions, and (2) no single LLM excels at all labeling tasks. To address these challenges, we leverage calibrated confidence scores to design a cost-aware cascading LLM ensemble policy which achieves improved accuracy while reducing inference cost by more than 2 times compared with the conventional weighted majority voting ensemble policy.},
  author = {Hovsepian, Karen and Liu, Dantong and Murugesan, Sugumar},
  doi = {10.48550/arXiv.2405.04323},
  journal = {Amazon Science},
  keywords = {type:Calibration，LLM, confidence calibration, ensemble methods, classification},
  number = {N/A},
  publisher = {Amazon},
  volume = {N/A},
  series = {N/A},
  title = {Effective Confidence Calibration and Ensembles in LLM-Powered Classification},
  url = {https://www.amazon.science/publications/label-with-confidence-effective-confidence-calibration-and-ensembles-in-llm-powered-classification},
  year = {2024}
}

@article{Zhou2025SemanticSteering,
  abstract = {Contrary to previous claims, we first rigorously confirm the existence of directional confidence shifts by probing three models (including GPT3.5, LLAMA3-70b, GPT4) across seven benchmarks, demonstrating that explicit instructions can inflate or deflate confidence scores in a regulated manner. Based on this observation, we propose a novel framework containing three components: confidence steering, steered confidence aggregation, and steered answers selection, named SteeringConf.},
  author = {Zhou, Ziang and Jin, Tianyuan and Shi, Jieming and Li, Qing},
  doi = {10.48550/arXiv.2503.02863},
  journal = {arXiv preprint arXiv:2503.02863},
  keywords = {type:Technique，LLM, confidence calibration, semantic steering, multi-prompt aggregation},
  number = {2503.02863},
  publisher = {arXiv},
  volume = {abs/2503.02863},
  series = {cs.CL},
  title = {Calibrating LLM Confidence with Semantic Steering: A Multi-Prompt Aggregation Framework},
  url = {https://arxiv.org/abs/2503.02863},
  year = {2025}
}

@article{Geng2024Survey,
  abstract = {Large language models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks in various domains. Despite their impressive performance, they can be unreliable due to factual errors in their generations. Assessing their confidence and calibrating them across different tasks can help mitigate risks and enable LLMs to produce better generations. There has been a lot of recent research aiming to address this, but there has been no comprehensive overview to organize it and outline the main lessons learned. The present survey aims to bridge this gap. In particular, we outline the challenges and we summarize recent technical advancements for LLM confidence estimation and calibration. We further discuss their applications and suggest promising directions for future work.}，
  author = {Geng, Jiahui and Cai, Fengyu},
  doi = {10.18653/v1/2024.naacl-long.366},
  journal = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  keywords = {type:Survey，LLM, confidence estimation, calibration, survey},
  number = {366},
  publisher = {ACL},
  volume = {N/A},
  series = {NAACL},
  title = {A Survey of Confidence Estimation and Calibration in Large Language Models},
  url = {https://aclanthology.org/2024.naacl-long.366/},
  year = {2024}
}

@article{Messer2023Review,
  abstract = {We conducted a systematic literature review on automated grading and feedback tools for programming education. We analyzed 121 research papers from 2017 to 2021 inclusive and categorized them based on skills assessed, approach, language paradigm, degree of automation, and evaluation techniques. Most papers assess the correctness of assignments in object-oriented languages.}，
  author = {Messer, Marcus and Brown, Neil and Kölling, Michael and Shi, Miaojing},
  doi = {10.1145/3636515},
  journal = {ACM Transactions on Computing Education},
  keywords = {type:Survey，automated grading, programming education, feedback tools, systematic review},
  number = {N/A},
  publisher = {ACM},
  volume = {N/A},
  series = {TOCE},
  title = {Automated Grading and Feedback Tools for Programming Education: A Systematic Review},
  url = {https://dl.acm.org/doi/10.1145/3636515},
  year = {2023}
}

@inproceedings{Malik2019GenerativeGrading,
  abstract = {Access to high-quality education at scale is limited by the difficulty of providing student feedback on open-ended assignments in structured domains like programming, graphics, and short response questions. This problem has proven to be exceptionally difficult: for humans, it requires large amounts of manual work, and for computers, until recently, achieving anything near human-level accuracy has been unattainable. In this paper, we present generative grading: a novel computational approach for providing feedback at scale that is capable of both accurately grading student work while also providing verifiability—a property where the model is able to substantiate its claims with a provable certificate.}，
  author = {Malik, Ali and Wu, Mike and Vasavada, Vrinda and Song, Jinpeng and Coots, Madison and Mitchell, John and Goodman, Noah D. and Piech, Chris},
  doi = {10.48550/arXiv.1905.09916},
  journal = {Proceedings of the 14th International Conference on Educational Data Mining (EDM 2021)},
  keywords = {type:Technique，automated grading, neural approximate parsing, student feedback, generative models},
  number = {N/A},
  publisher = {International Educational Data Mining Society},
  volume = {N/A},
  series = {EDM},
  title = {Generative Grading: Neural Approximate Parsing for Automated Student Feedback},
  url = {https://arxiv.org/abs/1905.09916},
  year = {2021}
}

